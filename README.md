# Textual-Visual-Alignment-and-Fusion-NetWork
Source codes of the our paper titled "Multi-level Textual-Visual Alignment and Fusion Network for Multimodal Aspect-based Sentiment Analysis"

## Dataset
- For visual objects in dataset, we perform [YOLOv5x6](https://docs.ultralytics.com/yolov5/) to detect objects.
- Applying the [ClipCap](https://github.com/rmokady/CLIP_prefix_caption) to generate image captions.
- The face descriptions from the raw images from [FITE]([https://github.com/NUSTM/VLP-MABSA](https://github.com/yhit98/FITE)), many thanks.
- The OCR text of images extracted from Google's Tesseract OCR engine.
- Obtained ANPs of each image following the image preprocessing procedure of [VLP-MABSA](https://github.com/NUSTM/VLP-MABSA).
- Twitter2015 and Twitter2017 from [BaiduNetdisk](链接：https://pan.baidu.com/s/18V3eR16yQ6DI4uOgo1AZVQ 提取码：5fyu )
